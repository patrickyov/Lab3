{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2H4rNmz9QMoq"
   },
   "source": [
    "<div>\n",
    "<img src=https://www.institutedata.com/wp-content/uploads/2019/10/iod_h_tp_primary_c.svg width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-z0xtWELQMot"
   },
   "source": [
    "# Lab 3.2.3\n",
    "# *Google BigQuery and Gemini API*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fyl3eBVAQMox"
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDR6T_maQMo0"
   },
   "source": [
    "The Google BigQuery UI provides access to Google's extensive collection of public data sets via an SQL-based query engine.\n",
    "\n",
    "The BigQuery API provides programmatic access to the data sets.\n",
    "\n",
    "The Google Gemini API provides programmatic access to Google's Generative AI models.\n",
    "\n",
    "Each of these is explored in this lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g2EqZVSGQMo3"
   },
   "source": [
    "## BigQuery Web UI\n",
    "\n",
    "The Google BigQuery UI can be used to discover interesting data before writing Python code to access it. Then we can reproduce it in an API request so as to aggregate large amounts of data on Google's infrastructure before pulling the results into our application.\n",
    "\n",
    "Work through the Quickstart at https://cloud.google.com/bigquery/docs/quickstarts/quickstart-web-ui.\n",
    "\n",
    "You will need to set up a Google Cloud Platform account if you don't already have one. (This should not cost anything during the trial period unless you perform a large amount of querying. Afterwards, costs are based on actual resource usage, but most offerings have a free tier.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JM7ACBFEQMo6"
   },
   "source": [
    "## BigQuery API\n",
    "\n",
    "- Open Google Cloud Console (https://console.cloud.google.com/home/) and select to create a project. A project is required to enable access to Google Cloud services such as BigQuery and Gemini.\n",
    "\n",
    "- Check that the BigQuery API is enabled in your project by visiting https://console.cloud.google.com/apis/library/bigquery.googleapis.com."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "peKoqVLaQMpA"
   },
   "source": [
    "### Authentication\n",
    "\n",
    "Create a **service account** at https://console.cloud.google.com/iam-admin/serviceaccounts/create. A service account is used by an application to access Google Cloud Platform's services and has an associated email address (different from your own).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RprZFRn6QMpB"
   },
   "source": [
    "- Give the account an appropriate name, and under step 2 (Grant this service account access to project (optional)), choose \"Owner\" under the \"Select a Role\" dropdown.\n",
    "\n",
    "- Ignore step 3 and click \"Done\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vs9LutadQMpD"
   },
   "source": [
    "Go to https://console.cloud.google.com/iam-admin/serviceaccounts to create a **service account key**. This will be downloaded to your computer so that you can connect to the BigQuery API via this Jupyter notebook.\n",
    "\n",
    "- Select your recently created project.\n",
    "- Click the email address of the service account.\n",
    "- Click the Keys tab.\n",
    "- Click the Add key drop-down menu, then select Create new key.\n",
    "- Select JSON as the Key type and click Create.\n",
    "- The keys will get saved to your computer.\n",
    "\n",
    "Note the location and copy the file path (of the json file) to somewhere safe, for future reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F4c4B7yHQMpH"
   },
   "source": [
    "See here for more information:\n",
    "\n",
    "Service Account creation: https://cloud.google.com/iam/docs/service-accounts-create#creating (under Console)\n",
    "\n",
    "Service Account key creation: https://cloud.google.com/iam/docs/keys-create-delete#iam-service-account-keys-create-console (under Console)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LycUcpuhQMpK"
   },
   "source": [
    "### Using the Python API\n",
    "\n",
    "Google provides Python libraries for wrapping the Google APIs.\n",
    "\n",
    "Installing the \"google-cloud-bigquery\", \"google-cloud-storage\", and \"google-cloud-bigquery-storage\" libraries should cover all the dependencies for the BigQuery section of this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OrjH1yqXxpwe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Collecting google-cloud-bigquery\n",
      "  Downloading google_cloud_bigquery-3.34.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting google-api-core<3.0.0,>=2.11.1 (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery)\n",
      "  Downloading google_api_core-2.25.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-auth<3.0.0,>=2.14.1 (from google-cloud-bigquery)\n",
      "  Downloading google_auth-2.40.3-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting google-cloud-core<3.0.0,>=2.4.1 (from google-cloud-bigquery)\n",
      "  Using cached google_cloud_core-2.4.3-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-resumable-media<3.0.0,>=2.0.0 (from google-cloud-bigquery)\n",
      "  Using cached google_resumable_media-2.7.2-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: packaging>=24.2.0 in c:\\users\\patri\\anaconda3\\lib\\site-packages (from google-cloud-bigquery) (25.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in c:\\users\\patri\\anaconda3\\lib\\site-packages (from google-cloud-bigquery) (2.9.0.post0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.21.0 in c:\\users\\patri\\anaconda3\\lib\\site-packages (from google-cloud-bigquery) (2.32.4)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core<3.0.0,>=2.11.1->google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery)\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in c:\\users\\patri\\anaconda3\\lib\\site-packages (from google-api-core<3.0.0,>=2.11.1->google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (4.25.3)\n",
      "Collecting proto-plus<2.0.0,>=1.22.3 (from google-api-core<3.0.0,>=2.11.1->google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery)\n",
      "  Using cached proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting grpcio<2.0.0,>=1.33.2 (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery)\n",
      "  Downloading grpcio-1.73.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery)\n",
      "  Downloading grpcio_status-1.73.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\patri\\anaconda3\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\patri\\anaconda3\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.0,>=2.14.1->google-cloud-bigquery)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0 (from google-resumable-media<3.0.0,>=2.0.0->google-cloud-bigquery)\n",
      "  Downloading google_crc32c-1.7.1-cp312-cp312-win_amd64.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\patri\\anaconda3\\lib\\site-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery) (1.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\patri\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\patri\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\patri\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\patri\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (2025.6.15)\n",
      "Collecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 (from google-api-core<3.0.0,>=2.11.1->google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery)\n",
      "  Using cached protobuf-6.31.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\patri\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (0.4.8)\n",
      "Downloading google_cloud_bigquery-3.34.0-py3-none-any.whl (253 kB)\n",
      "Downloading google_api_core-2.25.1-py3-none-any.whl (160 kB)\n",
      "Downloading google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\n",
      "Using cached google_cloud_core-2.4.3-py2.py3-none-any.whl (29 kB)\n",
      "Using cached google_resumable_media-2.7.2-py2.py3-none-any.whl (81 kB)\n",
      "Downloading google_crc32c-1.7.1-cp312-cp312-win_amd64.whl (33 kB)\n",
      "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Downloading grpcio-1.73.0-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 2.4/4.3 MB 11.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 4.2/4.3 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 9.7 MB/s eta 0:00:00\n",
      "Downloading grpcio_status-1.73.0-py3-none-any.whl (14 kB)\n",
      "Using cached proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached protobuf-6.31.1-cp310-abi3-win_amd64.whl (435 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Installing collected packages: rsa, protobuf, grpcio, google-crc32c, proto-plus, googleapis-common-protos, google-resumable-media, google-auth, grpcio-status, google-api-core, google-cloud-core, google-cloud-bigquery\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.3\n",
      "    Uninstalling protobuf-4.25.3:\n",
      "      Successfully uninstalled protobuf-4.25.3\n"
     ]
    }
   ],
   "source": [
    "!pip install google-cloud-bigquery\n",
    "!pip install google-cloud-storage\n",
    "!pip install google-cloud-bigquery-storage # has additional capabilities for reading data from BigQuery using the BigQuery Storage API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-storage in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (3.1.0)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=2.26.1 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from google-cloud-storage) (2.38.0)\n",
      "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from google-cloud-storage) (2.24.2)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.4.2 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from google-cloud-storage) (2.4.3)\n",
      "Requirement already satisfied: google-resumable-media>=2.7.2 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from google-cloud-storage) (2.7.2)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from google-cloud-storage) (2.32.3)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from google-cloud-storage) (1.7.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage) (1.69.2)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage) (5.29.4)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage) (1.26.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (4.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2025.1.31)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.26.1->google-cloud-storage) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-cloud-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-bigquery-storage\n",
      "  Downloading google_cloud_bigquery_storage-2.32.0-py3-none-any.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-bigquery-storage) (2.24.2)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from google-cloud-bigquery-storage) (2.38.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.0 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from google-cloud-bigquery-storage) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from google-cloud-bigquery-storage) (5.29.4)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-bigquery-storage) (1.69.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-bigquery-storage) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-bigquery-storage) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-bigquery-storage) (1.71.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-bigquery-storage) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-bigquery-storage) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-bigquery-storage) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-cloud-bigquery-storage) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-bigquery-storage) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-bigquery-storage) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-bigquery-storage) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-bigquery-storage) (2025.1.31)\n",
      "Downloading google_cloud_bigquery_storage-2.32.0-py3-none-any.whl (296 kB)\n",
      "Installing collected packages: google-cloud-bigquery-storage\n",
      "Successfully installed google-cloud-bigquery-storage-2.32.0\n"
     ]
    }
   ],
   "source": [
    "!pip install google-cloud-bigquery-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "eKCOlUl8QMpL"
   },
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery_storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJfytyHnQMpZ"
   },
   "source": [
    "Invoke a method of the `.Client` object that takes the path to your key files as a string argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-L6z5aQRQMpZ"
   },
   "outputs": [],
   "source": [
    "key_path = 'C:/Users/patri/OneDrive/UTS and personal doc 2022/Documents/Person Docs/Data science program/Labs 3/flowing-athlete-463605-r9-2e11aba30b0c.json'  #Change this to match your key filename\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "00HRXCrbQMpb"
   },
   "source": [
    "This should not throw an error if key retrieval / assignment worked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "EaI5dybYQMpc"
   },
   "outputs": [],
   "source": [
    "storage_client = storage.Client.from_service_account_json(key_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XyF90p35QMpf"
   },
   "source": [
    "*Nb. The `storage` object was used in the above example, but there are other objects of interest that have polymorphic `Client` members that are used similarly, such as `bigquery`, which is used below.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U2ejMLo5QMpj"
   },
   "source": [
    "Next, execute this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Lwfj-eI5QMpk"
   },
   "outputs": [],
   "source": [
    "client = bigquery.Client.from_service_account_json(key_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpF3Gu-iQMpm"
   },
   "source": [
    "This client is associated with the default project (which was set or defaulted in the BigQuery UI):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "kO2v-luMQMpn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'flowing-athlete-463605-r9'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w_pX9XbnQMpr"
   },
   "source": [
    "A BigQuery project contains datasets. Datasets contain tables. To get at the data in a table we need to create a reference that covers this hierarchy; in the `bigquery` library this looks like `project.dataset.table`.  \n",
    "\n",
    "(Nb. Queries can be performed on projects and datasets, but most queries are performed on tables.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyJVwEuyQMps"
   },
   "source": [
    "To explore the public datasets we will start by reassigning our `client` variable using optional `project` parameter (set to `bigquery-public-data`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "cqpyCYo5QMps"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigquery-public-data\n"
     ]
    }
   ],
   "source": [
    "#project = 'bigquery-public-data'\n",
    "client = bigquery.Client.from_service_account_json(key_path, project = 'bigquery-public-data')\n",
    "print(client.project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MLI1MOiqQMpw"
   },
   "source": [
    "Here is how to get a list of the datasets in the current project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_81SBSwKQMpx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB1001450>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31AF650>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB2CE1590>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FA1E5FED0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31A2C90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31A1D10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31A2510>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31A1310>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FA1E65750>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31A1C50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31B4610>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31B7090>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31B4F90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31B4510>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31B6FD0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31B6F10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31B6ED0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31B4D10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31CC4D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31CC590>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31CC510>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31CC550>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31CD510>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31CD390>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31CD2D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31CD290>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31CD250>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31CD1D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31CD210>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31CD190>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31CCCD0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31CD150>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31CC350>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31CD490>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31CC390>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31CD450>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31CD410>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31CD3D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31CD310>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31CC610>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DB210>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DB250>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DB290>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DB2D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DB310>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DB350>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DB390>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DB3D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DB410>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DB450>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31AF590>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB317BC10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB317BC50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DB490>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DB4D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DB510>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DB610>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DB550>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DB590>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DBA50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DB910>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DB990>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DB950>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DBF90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DBFD0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DBED0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DBE50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31B50D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31B67D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31B6690>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31CD050>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31CD0D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31CCF90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31CD110>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31CD010>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31CCED0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31CCE90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31D0550>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31D0090>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31D0050>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31D0450>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31D04D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31D0490>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31D0D50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31D0750>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31D0290>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31D0650>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31D0710>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31D0510>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31D0CD0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31D0610>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31D0C90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31D0790>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31D0C50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31D06D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31D05D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E66D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E6710>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E6750>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E6790>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31AE5D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31B4D50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DB690>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DB6D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DB5D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DBE10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31CCDD0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31D0B50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31D0A90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31D0AD0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31D0B10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31D0A10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31D0910>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31D09D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31D07D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31D0950>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31D08D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E67D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E6810>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E6850>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E6890>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E68D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E6990>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E6D10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E6CD0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E6C10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E6C90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E6C50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E7190>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E7210>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E71D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E70D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E6F50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E6DD0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E74D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E7410>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E7510>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E7A90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E6B10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E7490>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E7A10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E73D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E79D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E7990>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E7950>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E7590>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E7110>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DF8D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DF910>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DF950>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DBA10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31CD090>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31CCF10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31CCFD0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DF990>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DF9D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DFA10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DFB10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DFA50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DFA90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DFED0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DFE90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DFDD0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DFE50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DFE10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DFF90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DFC50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31D0C10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E6A10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E6950>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E7850>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E7790>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E77D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E7810>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E7610>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E7690>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E75D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E7090>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E6BD0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E7650>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F0390>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F0450>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F0410>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F03D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F02D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F0350>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F0750>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F0650>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F0150>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F0CD0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F06D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F0C50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F0610>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F0C10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F0BD0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F0B90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F07D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F0710>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F39D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F3A10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DB810>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31CCB50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DFAD0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DFBD0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DFB50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31D0A50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E78D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F3A50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F3A90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F3AD0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F3BD0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F3B10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F3B50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F0A90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F3F90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F3F50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F3E90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F3F10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F3ED0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F09D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F3D50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F0A10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F0A50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F0850>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F08D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F0810>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F0290>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F0050>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F0890>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3204410>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB32044D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3204490>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3204390>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3204210>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3204090>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3204790>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB32046D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB32047D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3204D50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3204750>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3204CD0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3204690>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3204C90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3204C50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3204C10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3204850>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB32043D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3215910>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3215950>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3215990>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F3CD0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F3B90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F3C90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DBC50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31DB890>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E7450>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E7890>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31E72D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31CC710>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31CCD10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31CCC90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3204B10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3204A50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3204710>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3204A90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3204590>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3204AD0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB32048D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3204950>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3204890>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3204350>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3204110>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3204910>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB32159D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3215A10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3215A50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3215B50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3215A90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3215AD0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3215F10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3215ED0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3215E10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3215E90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3215E50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3216390>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3216410>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB32163D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB32162D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3216150>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3215FD0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB32166D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3216610>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3216710>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3216C90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3215D10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3216690>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3216C10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB32165D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3216BD0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3216B90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F0B10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F0690>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F0950>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB31F0AD0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3204BD0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3215C10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3215B90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3216B50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3216790>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3216310>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3216A50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3216990>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB32169D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3216A10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3216810>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3216890>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB32167D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3216290>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3215DD0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3216850>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB32244D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3224410>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3224450>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3224890>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3224850>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3224790>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3224810>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB32247D0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3224CD0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3224D90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3224D50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3224C50>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3224AD0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3224950>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3224FD0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3224F10>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3225010>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3225610>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3224BD0>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3224F90>, <google.cloud.bigquery.dataset.DatasetListItem object at 0x0000010FB3225590>]\n"
     ]
    }
   ],
   "source": [
    "datasets = list(client.list_datasets())\n",
    "print(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WsLMF5p_QMp2"
   },
   "source": [
    "That wasn't helpful. We need to go deeper into the object structure to get at something meaningful. Below is a function that exploits the `format` method of `project` and `dataset_id`, providing an easy way to list datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "afIVw6FNQMp6"
   },
   "outputs": [],
   "source": [
    "# function for listing datasets in a project:\n",
    "def printDatasetList(client):\n",
    "    project = client.project    #: only one project can be associated with a client instance\n",
    "    datasets = list(client.list_datasets())\n",
    "    if datasets:\n",
    "        print('Datasets in project {}:'.format(project))\n",
    "        for dataset in datasets:\n",
    "            print('\\t{}'.format(dataset.dataset_id))\n",
    "        found = True\n",
    "    else:\n",
    "        print('{} project does not contain any datasets.'.format(project))\n",
    "        found = False\n",
    "    return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "LHsC_THYQMp7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets in project bigquery-public-data:\n",
      "\tamerica_health_rankings\n",
      "\taustin_311\n",
      "\taustin_bikeshare\n",
      "\taustin_crime\n",
      "\taustin_incidents\n",
      "\taustin_waste\n",
      "\tbaseball\n",
      "\tbbc_news\n",
      "\tbigqueryml_ncaa\n",
      "\tbitcoin_blockchain\n",
      "\tblackhole_database\n",
      "\tblockchain_analytics_ethereum_mainnet_us\n",
      "\tbls\n",
      "\tbls_qcew\n",
      "\tbreathe\n",
      "\tbroadstreet_adi\n",
      "\tcatalonian_mobile_coverage\n",
      "\tcatalonian_mobile_coverage_eu\n",
      "\tcensus_bureau_acs\n",
      "\tcensus_bureau_construction\n",
      "\tcensus_bureau_international\n",
      "\tcensus_bureau_usa\n",
      "\tcensus_opportunity_atlas\n",
      "\tcensus_utility\n",
      "\tcfpb_complaints\n",
      "\tchicago_crime\n",
      "\tchicago_taxi_trips\n",
      "\tclemson_dice\n",
      "\tcloud_storage_geo_index\n",
      "\tcms_codes\n",
      "\tcms_medicare\n",
      "\tcms_synthetic_patient_data_omop\n",
      "\tcountry_codes\n",
      "\tcovid19_aha\n",
      "\tcovid19_covidtracking\n",
      "\tcovid19_ecdc\n",
      "\tcovid19_ecdc_eu\n",
      "\tcovid19_genome_sequence\n",
      "\tcovid19_geotab_mobility_impact\n",
      "\tcovid19_geotab_mobility_impact_eu\n",
      "\tcovid19_google_mobility\n",
      "\tcovid19_google_mobility_eu\n",
      "\tcovid19_govt_response\n",
      "\tcovid19_italy\n",
      "\tcovid19_italy_eu\n",
      "\tcovid19_jhu_csse\n",
      "\tcovid19_jhu_csse_eu\n",
      "\tcovid19_nyt\n",
      "\tcovid19_open_data\n",
      "\tcovid19_open_data_eu\n",
      "\tcovid19_public_forecasts\n",
      "\tcovid19_public_forecasts_asia_ne1\n",
      "\tcovid19_rxrx19\n",
      "\tcovid19_symptom_search\n",
      "\tcovid19_tracking\n",
      "\tcovid19_usafacts\n",
      "\tcovid19_vaccination_access\n",
      "\tcovid19_vaccination_search_insights\n",
      "\tcovid19_weathersource_com\n",
      "\tcrypto_aptos_mainnet_us\n",
      "\tcrypto_aptos_testnet_us\n",
      "\tcrypto_band\n",
      "\tcrypto_bitcoin\n",
      "\tcrypto_bitcoin_cash\n",
      "\tcrypto_dash\n",
      "\tcrypto_dogecoin\n",
      "\tcrypto_ethereum\n",
      "\tcrypto_ethereum_classic\n",
      "\tcrypto_iotex\n",
      "\tcrypto_kusama\n",
      "\tcrypto_litecoin\n",
      "\tcrypto_multiversx_mainnet_eu\n",
      "\tcrypto_near_mainnet_us\n",
      "\tcrypto_polkadot\n",
      "\tcrypto_polygon\n",
      "\tcrypto_solana_mainnet_us\n",
      "\tcrypto_sui_mainnet_us\n",
      "\tcrypto_tezos\n",
      "\tcrypto_theta\n",
      "\tcrypto_zcash\n",
      "\tcrypto_zilliqa\n",
      "\tcymbal_investments\n",
      "\tdataflix_covid\n",
      "\tdataflix_traffic_safety\n",
      "\tdeepmind_alphafold\n",
      "\tdeps_dev_v1\n",
      "\tdimensions_ai_covid19\n",
      "\tebi_chembl\n",
      "\tebi_mgnify\n",
      "\tebi_surechembl\n",
      "\teclipse_megamovie\n",
      "\tepa_historical_air_quality\n",
      "\tethereum_blockchain\n",
      "\tetsi_technical_standards\n",
      "\tfaa\n",
      "\tfcc_political_ads\n",
      "\tfda_drug\n",
      "\tfda_food\n",
      "\tfdic_banks\n",
      "\tfec\n",
      "\tfhir_synthea\n",
      "\tga4_obfuscated_sample_ecommerce\n",
      "\tgbif\n",
      "\tgdelt_hathitrustbooks\n",
      "\tgdelt_internetarchivebooks\n",
      "\tgenomics_cannabis\n",
      "\tgenomics_rice\n",
      "\tgeo_census_blockgroups\n",
      "\tgeo_census_tracts\n",
      "\tgeo_international_ports\n",
      "\tgeo_openstreetmap\n",
      "\tgeo_us_boundaries\n",
      "\tgeo_us_census_places\n",
      "\tgeo_us_roads\n",
      "\tgeo_whos_on_first\n",
      "\tghcn_d\n",
      "\tghcn_m\n",
      "\tgithub_repos\n",
      "\tgnomAD\n",
      "\tgnomAD_asiane1\n",
      "\tgnomAD_eu\n",
      "\tgoog_blockchain_arbitrum_one_us\n",
      "\tgoog_blockchain_avalanche_contract_chain_us\n",
      "\tgoog_blockchain_cronos_mainnet_us\n",
      "\tgoog_blockchain_ethereum_goerli_us\n",
      "\tgoog_blockchain_ethereum_mainnet_us\n",
      "\tgoog_blockchain_fantom_opera_us\n",
      "\tgoog_blockchain_optimism_mainnet_us\n",
      "\tgoog_blockchain_polygon_mainnet_us\n",
      "\tgoog_blockchain_tron_mainnet_us\n",
      "\tgoogle_ads\n",
      "\tgoogle_ads_geo_mapping_asia_east1\n",
      "\tgoogle_ads_geo_mapping_asia_east2\n",
      "\tgoogle_ads_geo_mapping_asia_northeast1\n",
      "\tgoogle_ads_geo_mapping_asia_northeast2\n",
      "\tgoogle_ads_geo_mapping_asia_northeast3\n",
      "\tgoogle_ads_geo_mapping_asia_south1\n",
      "\tgoogle_ads_geo_mapping_asia_south2\n",
      "\tgoogle_ads_geo_mapping_asia_southeast1\n",
      "\tgoogle_ads_geo_mapping_asia_southeast2\n",
      "\tgoogle_ads_geo_mapping_australia_southeast1\n",
      "\tgoogle_ads_geo_mapping_australia_southeast2\n",
      "\tgoogle_ads_geo_mapping_eu\n",
      "\tgoogle_ads_geo_mapping_europe_central2\n",
      "\tgoogle_ads_geo_mapping_europe_north1\n",
      "\tgoogle_ads_geo_mapping_europe_southwest1\n",
      "\tgoogle_ads_geo_mapping_europe_west1\n",
      "\tgoogle_ads_geo_mapping_europe_west12\n",
      "\tgoogle_ads_geo_mapping_europe_west2\n",
      "\tgoogle_ads_geo_mapping_europe_west3\n",
      "\tgoogle_ads_geo_mapping_europe_west4\n",
      "\tgoogle_ads_geo_mapping_europe_west6\n",
      "\tgoogle_ads_geo_mapping_europe_west8\n",
      "\tgoogle_ads_geo_mapping_europe_west9\n",
      "\tgoogle_ads_geo_mapping_me_central1\n",
      "\tgoogle_ads_geo_mapping_me_central2\n",
      "\tgoogle_ads_geo_mapping_me_west1\n",
      "\tgoogle_ads_geo_mapping_northamerica_northeast1\n",
      "\tgoogle_ads_geo_mapping_northamerica_northeast2\n",
      "\tgoogle_ads_geo_mapping_southamerica_east1\n",
      "\tgoogle_ads_geo_mapping_southamerica_west1\n",
      "\tgoogle_ads_geo_mapping_us\n",
      "\tgoogle_ads_geo_mapping_us_central1\n",
      "\tgoogle_ads_geo_mapping_us_central2\n",
      "\tgoogle_ads_geo_mapping_us_east1\n",
      "\tgoogle_ads_geo_mapping_us_east4\n",
      "\tgoogle_ads_geo_mapping_us_east5\n",
      "\tgoogle_ads_geo_mapping_us_south1\n",
      "\tgoogle_ads_geo_mapping_us_west1\n",
      "\tgoogle_ads_geo_mapping_us_west2\n",
      "\tgoogle_ads_geo_mapping_us_west3\n",
      "\tgoogle_ads_geo_mapping_us_west4\n",
      "\tgoogle_ads_transparency_center\n",
      "\tgoogle_analytics_sample\n",
      "\tgoogle_books_ngrams_2020\n",
      "\tgoogle_cfe\n",
      "\tgoogle_cloud_release_notes\n",
      "\tgoogle_dei\n",
      "\tgoogle_patents_research\n",
      "\tgoogle_political_ads\n",
      "\tgoogle_trends\n",
      "\tgretel_synthetic_text_to_sql\n",
      "\thacker_news\n",
      "\thud_zipcode_crosswalk\n",
      "\thuman_genome_variants\n",
      "\thuman_variant_annotation\n",
      "\tidc_current\n",
      "\tidc_current_clinical\n",
      "\tidc_v1\n",
      "\tidc_v10\n",
      "\tidc_v11\n",
      "\tidc_v11_clinical\n",
      "\tidc_v12\n",
      "\tidc_v12_clinical\n",
      "\tidc_v13\n",
      "\tidc_v13_clinical\n",
      "\tidc_v14\n",
      "\tidc_v14_clinical\n",
      "\tidc_v15\n",
      "\tidc_v15_clinical\n",
      "\tidc_v16\n",
      "\tidc_v16_clinical\n",
      "\tidc_v17\n",
      "\tidc_v17_clinical\n",
      "\tidc_v18\n",
      "\tidc_v18_clinical\n",
      "\tidc_v19\n",
      "\tidc_v19_clinical\n",
      "\tidc_v2\n",
      "\tidc_v20\n",
      "\tidc_v20_clinical\n",
      "\tidc_v21\n",
      "\tidc_v21_clinical\n",
      "\tidc_v3\n",
      "\tidc_v4\n",
      "\tidc_v5\n",
      "\tidc_v6\n",
      "\tidc_v7\n",
      "\tidc_v8\n",
      "\tidc_v9\n",
      "\timdb\n",
      "\timmune_epitope_db\n",
      "\tiowa_liquor_sales\n",
      "\tiowa_liquor_sales_forecasting\n",
      "\tirs_990\n",
      "\tlabeled_patents\n",
      "\tlibraries_io\n",
      "\tlistenbrainz\n",
      "\tlondon_bicycles\n",
      "\tlondon_crime\n",
      "\tlondon_fire_brigade\n",
      "\tmarec\n",
      "\tmedicare\n",
      "\tml_datasets\n",
      "\tml_datasets_uscentral1\n",
      "\tmodis_terra_net_primary_production\n",
      "\tmoon_phases\n",
      "\tmultilingual_spoken_words_corpus\n",
      "\tnasa_wildfire\n",
      "\tnational_water_model\n",
      "\tncaa_basketball\n",
      "\tnces_ipeds\n",
      "\tnew_york\n",
      "\tnew_york_311\n",
      "\tnew_york_citibike\n",
      "\tnew_york_mv_collisions\n",
      "\tnew_york_subway\n",
      "\tnew_york_taxi_trips\n",
      "\tnew_york_trees\n",
      "\tnhtsa_traffic_fatalities\n",
      "\tnih_gudid\n",
      "\tnih_sequence_read\n",
      "\tnlm_rxnorm\n",
      "\tnoaa_global_forecast_system\n",
      "\tnoaa_goes16\n",
      "\tnoaa_goes17\n",
      "\tnoaa_gsod\n",
      "\tnoaa_historic_severe_storms\n",
      "\tnoaa_hurricanes\n",
      "\tnoaa_icoads\n",
      "\tnoaa_lightning\n",
      "\tnoaa_passive_acoustic_index\n",
      "\tnoaa_passive_bioacoustic\n",
      "\tnoaa_pifsc_metadata\n",
      "\tnoaa_preliminary_severe_storms\n",
      "\tnoaa_significant_earthquakes\n",
      "\tnoaa_tsunami\n",
      "\tnppes\n",
      "\tnrel_nsrdb\n",
      "\topen_buildings\n",
      "\topen_images\n",
      "\topen_targets_genetics\n",
      "\topen_targets_platform\n",
      "\topenaq\n",
      "\toverture_maps\n",
      "\tpatents\n",
      "\tpatents_cpc\n",
      "\tpatents_dsep\n",
      "\tpatents_view\n",
      "\tpersistent_udfs\n",
      "\tproperati_properties_ar\n",
      "\tproperati_properties_br\n",
      "\tproperati_properties_cl\n",
      "\tproperati_properties_co\n",
      "\tproperati_properties_mx\n",
      "\tproperati_properties_pe\n",
      "\tproperati_properties_uy\n",
      "\tpypi\n",
      "\trekor\n",
      "\tsamples\n",
      "\tsan_francisco\n",
      "\tsan_francisco_311\n",
      "\tsan_francisco_bikeshare\n",
      "\tsan_francisco_film_locations\n",
      "\tsan_francisco_neighborhoods\n",
      "\tsan_francisco_sffd_service_calls\n",
      "\tsan_francisco_sfpd_incidents\n",
      "\tsan_francisco_transit_muni\n",
      "\tsan_francisco_trees\n",
      "\tsdoh_bea_cainc30\n",
      "\tsdoh_cdc_wonder_natality\n",
      "\tsdoh_cms_dual_eligible_enrollment\n",
      "\tsdoh_hrsa_shortage_areas\n",
      "\tsdoh_hud_housing\n",
      "\tsdoh_hud_pit_homelessness\n",
      "\tsdoh_snap_enrollment\n",
      "\tsec_quarterly_financials\n",
      "\tstackoverflow\n",
      "\tsunroof_solar\n",
      "\tthe_general_index\n",
      "\tthe_met\n",
      "\tthelook_ecommerce\n",
      "\ttpc_ds_10t\n",
      "\ttravel_impact_model\n",
      "\tucb_fung_patent_data\n",
      "\tumiami_lincs\n",
      "\tun_sdg\n",
      "\tus_res_real_est_data\n",
      "\tusa_contagious_disease\n",
      "\tusa_names\n",
      "\tusda_nass_agriculture\n",
      "\tusfs_fia\n",
      "\tusitc_investigations\n",
      "\tuspto_oce_assignment\n",
      "\tuspto_oce_cancer\n",
      "\tuspto_oce_claims\n",
      "\tuspto_oce_litigation\n",
      "\tuspto_oce_office_actions\n",
      "\tuspto_oce_pair\n",
      "\tuspto_ptab\n",
      "\tutility_eu\n",
      "\tutility_us\n",
      "\twikipedia\n",
      "\twise_all_sky_data_release\n",
      "\tworld_bank_global_population\n",
      "\tworld_bank_health_population\n",
      "\tworld_bank_intl_debt\n",
      "\tworld_bank_intl_education\n",
      "\tworld_bank_wdi\n",
      "\tworldbank_wdi\n",
      "\tworldpop\n"
     ]
    }
   ],
   "source": [
    "# list datasets in the default project:\n",
    "flag = printDatasetList(client)  #: assigning to `flag` suppresses printing the return value (normally `True`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PUB7M5KEQMp-"
   },
   "source": [
    "This list should correspond to what is shown here https://bigquery.cloud.google.com/publicdatasets under the **bigquery-public-data** item."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eGTZqizQMp-"
   },
   "source": [
    "Here is how to create a dataset reference object by assigning a project and a dataset name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Rja9NOTyQMp_"
   },
   "outputs": [],
   "source": [
    "dataset_id = 'samples'\n",
    "dataset_ref = client.dataset(dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wVeBwg8JQMqB"
   },
   "source": [
    "If our current project was something other than `bigquery-public-data`, we could still create this reference by specifying the project that contains the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "pUcHVtXYQMqB"
   },
   "outputs": [],
   "source": [
    "dataset_id = 'samples'\n",
    "dataset_ref = client.dataset(dataset_id, project = 'bigquery-public-data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JfrckJFYQMqE"
   },
   "source": [
    "How can we get the path of the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "aqKCkd8zQMqE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/projects/bigquery-public-data/datasets/samples'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER:\n",
    "dataset_ref.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fz7DDChLQMqH"
   },
   "source": [
    "Explore more of this object's members:\n",
    "\n",
    "*(HINT: You can type `dataset_ref.` in a new line, then hit the [Tab] key to see the available members for the object.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bigquery-public-data'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#?\n",
    "dataset_ref.project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBPXcGciQMqJ"
   },
   "source": [
    "Here is a function for listing the tables in a dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "yLvSI1HiQMqK"
   },
   "outputs": [],
   "source": [
    "# function for listing tables in a dataset:\n",
    "def printTableList(client, dataset_id):\n",
    "    project = client.project\n",
    "    dataset_ref = client.dataset(dataset_id, project = project)\n",
    "    tables = list(client.list_tables(dataset_ref))\n",
    "    if tables:\n",
    "        print('Tables in dataset {}:'.format(dataset_id))\n",
    "        for table in tables:\n",
    "            print('\\t{}'.format(table.table_id))\n",
    "        found = True\n",
    "    else:\n",
    "        print('{} dataset does not contain any tables.'.format(dataset_id))\n",
    "        found = False\n",
    "    return found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a-K9gx_ZQMqL"
   },
   "source": [
    "Use this function to list the tables in the current dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "iQVbZwLRQMqL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in dataset samples:\n",
      "\tgithub_nested\n",
      "\tgithub_timeline\n",
      "\tgsod\n",
      "\tnatality\n",
      "\tshakespeare\n",
      "\ttrigrams\n",
      "\twikipedia\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "printTableList(client, dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F6CzLw6YQMqN"
   },
   "source": [
    "To create a reference to a table within the dataset, we use the `table_id` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "OIAuOmziQMqO"
   },
   "outputs": [],
   "source": [
    "table_id = 'shakespeare'\n",
    "table_ref = dataset_ref.table(table_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A7LCWxz9QMqQ"
   },
   "source": [
    "To access the data in the table itself, we use the `get_table()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "l0-fX9j0QMqR"
   },
   "outputs": [],
   "source": [
    "table = client.get_table(table_ref)  # API Request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TuWzIYpEQMqS"
   },
   "source": [
    "NOTE: The contents of the table are not actually in our memory after this call! We are working with a Big Data platform, now, and we could easily end up pulling GBs or TBs of data by accident.\n",
    "\n",
    "To minimise data bandwidth, memory consumption, and processing time, Big Data platforms employ ***lazy evaluation***. This means that no computation or data transfer actually takes place until we *realise* (use) the data. Even if we execute subsequent code that performs calculations on the data, no data flow or computation actually occurs until we request output (e.g. by executing a print to stdout or writing to a file)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A5sefu0lQMqS"
   },
   "source": [
    "What kind of object is returned by `client.get_table`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "kF-aRGZsQMqS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'google.cloud.bigquery.table.Table'>\n"
     ]
    }
   ],
   "source": [
    "#ANSWER:\n",
    "\n",
    "print(type(table))  # Output: <class 'google.cloud.bigquery.table.Table'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fPiGLOjnQMqU"
   },
   "source": [
    "How can we view the design of the table (column names and types)? The name of the object attribute we need is the same term we learned in the module on databases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "lBNJqT9EQMqU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SchemaField('word', 'STRING', 'REQUIRED', None, 'A single unique word (where whitespace is the delimiter) extracted from a corpus.', (), None), SchemaField('word_count', 'INTEGER', 'REQUIRED', None, 'The number of times this word appears in this corpus.', (), None), SchemaField('corpus', 'STRING', 'REQUIRED', None, 'The work from which this word was extracted.', (), None), SchemaField('corpus_date', 'INTEGER', 'REQUIRED', None, 'The year in which this corpus was published.', (), None)]\n"
     ]
    }
   ],
   "source": [
    "#ANSWER\n",
    "print(table.schema)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iGrt3XsIQMqW"
   },
   "source": [
    "Again, this is messy. If we wanted to refer to the column names and types in code, we might use something like this (which we could then parse into a dict):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "G27W0Q9QQMqX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['word STRING', 'word_count INTEGER', 'corpus STRING', 'corpus_date INTEGER']\n"
     ]
    }
   ],
   "source": [
    "result = [\"{0} {1}\".format(schema.name,schema.field_type) for schema in table.schema]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKV8IsmlQMqY"
   },
   "source": [
    "But if we just want to print them, here is another neat function for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "m1uf0jPxQMqZ"
   },
   "outputs": [],
   "source": [
    "# function to print a table schema:\n",
    "def printTableSchema(aTable):\n",
    "    schemas = list(aTable.schema)\n",
    "    if schemas:\n",
    "        print('Table schema for {}:'.format(aTable.table_id))\n",
    "        for aSchema in schemas:\n",
    "            print('\\t{0} {1}'.format(aSchema.name, aSchema.field_type))\n",
    "        found = True\n",
    "    else:\n",
    "        found = False\n",
    "    return found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3-l8kOkVQMqa"
   },
   "source": [
    "Use this function to print the table schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "zc10udqtQMqa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table schema for shakespeare:\n",
      "\tword STRING\n",
      "\tword_count INTEGER\n",
      "\tcorpus STRING\n",
      "\tcorpus_date INTEGER\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER:\n",
    "printTableSchema(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b8CKkZBPQMqc"
   },
   "source": [
    "Now that we know what the columns are, we can write queries. Actually, we construct a query job by assigning an SQL statement to a method of the `client` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "yfsmLuJHQMqd"
   },
   "outputs": [
    {
     "ename": "Forbidden",
     "evalue": "403 POST https://bigquery.googleapis.com/bigquery/v2/projects/bigquery-public-data/jobs?prettyPrint=false: Access Denied: Project bigquery-public-data: User does not have bigquery.jobs.create permission in project bigquery-public-data.\n\nLocation: None\nJob ID: 3a0a9b3e-43f7-4806-915d-6fa62c23d521\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mForbidden\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m sql \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT COUNT(1) FROM bigquery-public-data.samples.shakespeare\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m query_job \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mquery(sql)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Cohort2\\Lib\\site-packages\\google\\cloud\\bigquery\\client.py:3502\u001b[0m, in \u001b[0;36mClient.query\u001b[1;34m(self, query, job_config, job_id, job_id_prefix, location, project, retry, timeout, job_retry, api_method)\u001b[0m\n\u001b[0;32m   3491\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _job_helpers\u001b[38;5;241m.\u001b[39mquery_jobs_query(\n\u001b[0;32m   3492\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   3493\u001b[0m         query,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3499\u001b[0m         job_retry,\n\u001b[0;32m   3500\u001b[0m     )\n\u001b[0;32m   3501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m api_method \u001b[38;5;241m==\u001b[39m enums\u001b[38;5;241m.\u001b[39mQueryApiMethod\u001b[38;5;241m.\u001b[39mINSERT:\n\u001b[1;32m-> 3502\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _job_helpers\u001b[38;5;241m.\u001b[39mquery_jobs_insert(\n\u001b[0;32m   3503\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   3504\u001b[0m         query,\n\u001b[0;32m   3505\u001b[0m         job_config,\n\u001b[0;32m   3506\u001b[0m         job_id,\n\u001b[0;32m   3507\u001b[0m         job_id_prefix,\n\u001b[0;32m   3508\u001b[0m         location,\n\u001b[0;32m   3509\u001b[0m         project,\n\u001b[0;32m   3510\u001b[0m         retry,\n\u001b[0;32m   3511\u001b[0m         timeout,\n\u001b[0;32m   3512\u001b[0m         job_retry,\n\u001b[0;32m   3513\u001b[0m     )\n\u001b[0;32m   3514\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3515\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot unexpected value for api_method: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(api_method)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Cohort2\\Lib\\site-packages\\google\\cloud\\bigquery\\_job_helpers.py:181\u001b[0m, in \u001b[0;36mquery_jobs_insert\u001b[1;34m(client, query, job_config, job_id, job_id_prefix, location, project, retry, timeout, job_retry)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m job_retry \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    179\u001b[0m     do_query \u001b[38;5;241m=\u001b[39m google\u001b[38;5;241m.\u001b[39mcloud\u001b[38;5;241m.\u001b[39mbigquery\u001b[38;5;241m.\u001b[39mretry\u001b[38;5;241m.\u001b[39m_DEFAULT_QUERY_JOB_INSERT_RETRY(do_query)\n\u001b[1;32m--> 181\u001b[0m future \u001b[38;5;241m=\u001b[39m do_query()\n\u001b[0;32m    183\u001b[0m \u001b[38;5;66;03m# The future might be in a failed state now, but if it's\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# unrecoverable, we'll find out when we ask for it's result, at which\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;66;03m# point, we may retry.\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m job_id_given:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Cohort2\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    292\u001b[0m )\n\u001b[1;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retry_target(\n\u001b[0;32m    294\u001b[0m     target,\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predicate,\n\u001b[0;32m    296\u001b[0m     sleep_generator,\n\u001b[0;32m    297\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout,\n\u001b[0;32m    298\u001b[0m     on_error\u001b[38;5;241m=\u001b[39mon_error,\n\u001b[0;32m    299\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Cohort2\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m     _retry_error_helper(\n\u001b[0;32m    154\u001b[0m         exc,\n\u001b[0;32m    155\u001b[0m         deadline,\n\u001b[0;32m    156\u001b[0m         sleep,\n\u001b[0;32m    157\u001b[0m         error_list,\n\u001b[0;32m    158\u001b[0m         predicate,\n\u001b[0;32m    159\u001b[0m         on_error,\n\u001b[0;32m    160\u001b[0m         exception_factory,\n\u001b[0;32m    161\u001b[0m         timeout,\n\u001b[0;32m    162\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Cohort2\\Lib\\site-packages\\google\\api_core\\retry\\retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[1;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[0;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[0;32m    208\u001b[0m         error_list,\n\u001b[0;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[0;32m    210\u001b[0m         original_timeout,\n\u001b[0;32m    211\u001b[0m     )\n\u001b[1;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Cohort2\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m target()\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[0;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Cohort2\\Lib\\site-packages\\google\\cloud\\bigquery\\_job_helpers.py:137\u001b[0m, in \u001b[0;36mquery_jobs_insert.<locals>.do_query\u001b[1;34m()\u001b[0m\n\u001b[0;32m    134\u001b[0m query_job \u001b[38;5;241m=\u001b[39m job\u001b[38;5;241m.\u001b[39mQueryJob(job_ref, query, client\u001b[38;5;241m=\u001b[39mclient, job_config\u001b[38;5;241m=\u001b[39mjob_config)\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     query_job\u001b[38;5;241m.\u001b[39m_begin(retry\u001b[38;5;241m=\u001b[39mretry, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core_exceptions\u001b[38;5;241m.\u001b[39mConflict \u001b[38;5;28;01mas\u001b[39;00m create_exc:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;66;03m# The thought is if someone is providing their own job IDs and they get\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;66;03m# their job ID generation wrong, this could end up returning results for\u001b[39;00m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;66;03m# the wrong query. We thus only try to recover if job ID was not given.\u001b[39;00m\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m job_id_given:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Cohort2\\Lib\\site-packages\\google\\cloud\\bigquery\\job\\query.py:1383\u001b[0m, in \u001b[0;36mQueryJob._begin\u001b[1;34m(self, client, retry, timeout)\u001b[0m\n\u001b[0;32m   1363\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"API call:  begin the job via a POST request\u001b[39;00m\n\u001b[0;32m   1364\u001b[0m \n\u001b[0;32m   1365\u001b[0m \u001b[38;5;124;03mSee\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1379\u001b[0m \u001b[38;5;124;03m    ValueError: If the job has already begun.\u001b[39;00m\n\u001b[0;32m   1380\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1382\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1383\u001b[0m     \u001b[38;5;28msuper\u001b[39m(QueryJob, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_begin(client\u001b[38;5;241m=\u001b[39mclient, retry\u001b[38;5;241m=\u001b[39mretry, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mGoogleAPICallError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m   1385\u001b[0m     exc\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m=\u001b[39m _EXCEPTION_FOOTER_TEMPLATE\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1386\u001b[0m         message\u001b[38;5;241m=\u001b[39mexc\u001b[38;5;241m.\u001b[39mmessage, location\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocation, job_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_id\n\u001b[0;32m   1387\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Cohort2\\Lib\\site-packages\\google\\cloud\\bigquery\\job\\base.py:748\u001b[0m, in \u001b[0;36m_AsyncJob._begin\u001b[1;34m(self, client, retry, timeout)\u001b[0m\n\u001b[0;32m    745\u001b[0m \u001b[38;5;66;03m# jobs.insert is idempotent because we ensure that every new\u001b[39;00m\n\u001b[0;32m    746\u001b[0m \u001b[38;5;66;03m# job has an ID.\u001b[39;00m\n\u001b[0;32m    747\u001b[0m span_attributes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m: path}\n\u001b[1;32m--> 748\u001b[0m api_response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39m_call_api(\n\u001b[0;32m    749\u001b[0m     retry,\n\u001b[0;32m    750\u001b[0m     span_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBigQuery.job.begin\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    751\u001b[0m     span_attributes\u001b[38;5;241m=\u001b[39mspan_attributes,\n\u001b[0;32m    752\u001b[0m     job_ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    753\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    754\u001b[0m     path\u001b[38;5;241m=\u001b[39mpath,\n\u001b[0;32m    755\u001b[0m     data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_api_repr(),\n\u001b[0;32m    756\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    757\u001b[0m )\n\u001b[0;32m    758\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_properties(api_response)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Cohort2\\Lib\\site-packages\\google\\cloud\\bigquery\\client.py:843\u001b[0m, in \u001b[0;36mClient._call_api\u001b[1;34m(self, retry, span_name, span_attributes, job_ref, headers, **kwargs)\u001b[0m\n\u001b[0;32m    839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    840\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m create_span(\n\u001b[0;32m    841\u001b[0m         name\u001b[38;5;241m=\u001b[39mspan_name, attributes\u001b[38;5;241m=\u001b[39mspan_attributes, client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, job_ref\u001b[38;5;241m=\u001b[39mjob_ref\n\u001b[0;32m    842\u001b[0m     ):\n\u001b[1;32m--> 843\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m call()\n\u001b[0;32m    845\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m call()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Cohort2\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    292\u001b[0m )\n\u001b[1;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retry_target(\n\u001b[0;32m    294\u001b[0m     target,\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predicate,\n\u001b[0;32m    296\u001b[0m     sleep_generator,\n\u001b[0;32m    297\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout,\n\u001b[0;32m    298\u001b[0m     on_error\u001b[38;5;241m=\u001b[39mon_error,\n\u001b[0;32m    299\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Cohort2\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m     _retry_error_helper(\n\u001b[0;32m    154\u001b[0m         exc,\n\u001b[0;32m    155\u001b[0m         deadline,\n\u001b[0;32m    156\u001b[0m         sleep,\n\u001b[0;32m    157\u001b[0m         error_list,\n\u001b[0;32m    158\u001b[0m         predicate,\n\u001b[0;32m    159\u001b[0m         on_error,\n\u001b[0;32m    160\u001b[0m         exception_factory,\n\u001b[0;32m    161\u001b[0m         timeout,\n\u001b[0;32m    162\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Cohort2\\Lib\\site-packages\\google\\api_core\\retry\\retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[1;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[0;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[0;32m    208\u001b[0m         error_list,\n\u001b[0;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[0;32m    210\u001b[0m         original_timeout,\n\u001b[0;32m    211\u001b[0m     )\n\u001b[1;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Cohort2\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m target()\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[0;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Cohort2\\Lib\\site-packages\\google\\cloud\\_http\\__init__.py:494\u001b[0m, in \u001b[0;36mJSONConnection.api_request\u001b[1;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object, timeout, extra_api_info)\u001b[0m\n\u001b[0;32m    482\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    483\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    484\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m     extra_api_info\u001b[38;5;241m=\u001b[39mextra_api_info,\n\u001b[0;32m    491\u001b[0m )\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 494\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_http_response(response)\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m expect_json \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent:\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "\u001b[1;31mForbidden\u001b[0m: 403 POST https://bigquery.googleapis.com/bigquery/v2/projects/bigquery-public-data/jobs?prettyPrint=false: Access Denied: Project bigquery-public-data: User does not have bigquery.jobs.create permission in project bigquery-public-data.\n\nLocation: None\nJob ID: 3a0a9b3e-43f7-4806-915d-6fa62c23d521\n"
     ]
    }
   ],
   "source": [
    "sql = \"SELECT COUNT(1) FROM bigquery-public-data.samples.shakespeare\"\n",
    "query_job = client.query(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CAaHnxvuQMqf"
   },
   "source": [
    "This will throw an error since we don't have permission to create queries inside the `bigquery-public-data` project. Instead we set the project to our BigQuery project name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "5D9V0KjiQMqf"
   },
   "outputs": [],
   "source": [
    "client = bigquery.Client.from_service_account_json(key_path, project = 'flowing-athlete-463605-r9') #<<< your BigQuery project ID here!\n",
    "\n",
    "query_job = client.query(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "79jeDjSUQMqg"
   },
   "source": [
    "If that worked, show what query_job is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client project: flowing-athlete-463605-r9\n"
     ]
    }
   ],
   "source": [
    "print(\"Client project:\", client.project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "google.cloud.bigquery.job.query.QueryJob"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(query_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "9-cJTROVxpw0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QueryJob<project=flowing-athlete-463605-r9, location=US, id=9ba84a1d-0e39-4c91-b27c-1f09ae998f86>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ANSWER\n",
    "query_job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k9lZ6v0cQMqi"
   },
   "source": [
    "Once again, due to lazy execution, no actual execution occurs until we request output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "SSw6zneJQMqi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row((164656,), {'f0_': 0})\n"
     ]
    }
   ],
   "source": [
    "for row in query_job:  # API request - fetches results\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ItvCscRsQMqk"
   },
   "source": [
    "And, again, we need to manipulate this to make it neat. Each member of the rowset is a list and we only want to extract the value, which is in the first member:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "9rB2rpmoQMqk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164656\n"
     ]
    }
   ],
   "source": [
    "print(row[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UE_dP3i2QMqn"
   },
   "source": [
    "So, we now know that this table has 164,656 rows. (We would not want to print it!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hd4SdhDwQMqr"
   },
   "source": [
    "Write, execute, and print the results of a query that fetches 10 rows from the table, each containing the \"word\", \"word_count\", and \"corpus\" fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "KiQXzKCbQMqr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: LVII, Count: 1, Corpus: sonnets\n",
      "Word: augurs, Count: 1, Corpus: sonnets\n",
      "Word: dimm'd, Count: 1, Corpus: sonnets\n",
      "Word: plagues, Count: 1, Corpus: sonnets\n",
      "Word: treason, Count: 1, Corpus: sonnets\n",
      "Word: surmise, Count: 1, Corpus: sonnets\n",
      "Word: heed, Count: 1, Corpus: sonnets\n",
      "Word: Unthrifty, Count: 1, Corpus: sonnets\n",
      "Word: quality, Count: 1, Corpus: sonnets\n",
      "Word: wherever, Count: 1, Corpus: sonnets\n"
     ]
    }
   ],
   "source": [
    "#ANSWER\n",
    "# SQL to get 10 rows\n",
    "sql = \"\"\"\n",
    "    SELECT word, word_count, corpus\n",
    "    FROM `bigquery-public-data.samples.shakespeare`\n",
    "    LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "# Run query\n",
    "query_job = client.query(sql)\n",
    "\n",
    "# Print results\n",
    "for row in query_job.result():\n",
    "    print(f\"Word: {row.word}, Count: {row.word_count}, Corpus: {row.corpus}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o-_rW8ApQMqu"
   },
   "source": [
    "Whenever you catch yourself writing a swag of code to do something that seems rudimentary or low-level, there is a very good chance that you don't need to. A much easier way to handle the above requirement is to use the `to_dataframe` method of the QueryJob object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!{sys.executable} -m pip install db-dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "oZ25oiMOQMqu"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>word_count</th>\n",
       "      <th>corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LVII</td>\n",
       "      <td>1</td>\n",
       "      <td>sonnets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>augurs</td>\n",
       "      <td>1</td>\n",
       "      <td>sonnets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dimm'd</td>\n",
       "      <td>1</td>\n",
       "      <td>sonnets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>plagues</td>\n",
       "      <td>1</td>\n",
       "      <td>sonnets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>treason</td>\n",
       "      <td>1</td>\n",
       "      <td>sonnets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>surmise</td>\n",
       "      <td>1</td>\n",
       "      <td>sonnets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>heed</td>\n",
       "      <td>1</td>\n",
       "      <td>sonnets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Unthrifty</td>\n",
       "      <td>1</td>\n",
       "      <td>sonnets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>quality</td>\n",
       "      <td>1</td>\n",
       "      <td>sonnets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wherever</td>\n",
       "      <td>1</td>\n",
       "      <td>sonnets</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word  word_count   corpus\n",
       "0       LVII           1  sonnets\n",
       "1     augurs           1  sonnets\n",
       "2     dimm'd           1  sonnets\n",
       "3    plagues           1  sonnets\n",
       "4    treason           1  sonnets\n",
       "5    surmise           1  sonnets\n",
       "6       heed           1  sonnets\n",
       "7  Unthrifty           1  sonnets\n",
       "8    quality           1  sonnets\n",
       "9   wherever           1  sonnets"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = query_job.to_dataframe()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting db-dtypes\n",
      "  Downloading db_dtypes-1.4.3-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: numpy>=1.24.0 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from db-dtypes) (1.24.4)\n",
      "Requirement already satisfied: packaging>=24.2.0 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from db-dtypes) (24.2)\n",
      "Requirement already satisfied: pandas>=1.5.3 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from db-dtypes) (2.2.3)\n",
      "Collecting pyarrow>=13.0.0 (from db-dtypes)\n",
      "  Downloading pyarrow-20.0.0-cp311-cp311-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from pandas>=1.5.3->db-dtypes) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from pandas>=1.5.3->db-dtypes) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from pandas>=1.5.3->db-dtypes) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.5.3->db-dtypes) (1.16.0)\n",
      "Downloading db_dtypes-1.4.3-py3-none-any.whl (18 kB)\n",
      "Downloading pyarrow-20.0.0-cp311-cp311-win_amd64.whl (25.8 MB)\n",
      "   ---------------------------------------- 0.0/25.8 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.8/25.8 MB 11.2 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 4.2/25.8 MB 10.9 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 6.6/25.8 MB 10.9 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 8.9/25.8 MB 10.9 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 11.3/25.8 MB 11.0 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 13.4/25.8 MB 10.9 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 15.7/25.8 MB 11.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 17.8/25.8 MB 10.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 20.2/25.8 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 22.0/25.8 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 24.4/25.8 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.8/25.8 MB 10.3 MB/s eta 0:00:00\n",
      "Installing collected packages: pyarrow, db-dtypes\n",
      "Successfully installed db-dtypes-1.4.3 pyarrow-20.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install db-dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3iNOJ-cnQMqv"
   },
   "source": [
    "#### Additional Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1DFF38wvQMqv"
   },
   "source": [
    "1. Here is a readable way to code long SQL statements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "C1rUFwnnQMqv"
   },
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "    SELECT word, word_count, corpus\n",
    "    FROM bigquery-public-data.samples.shakespeare\n",
    "    LIMIT 10\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ey8f9Hg_QMqw"
   },
   "source": [
    "2. If you had an application that needed to modify the tables or datasets in the `bigquery-public-data` is project, you could copy them to our own project, where you would have the permissions to do as you please with the data (subject to Google's terms of use)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bMrmiDRJQMqw"
   },
   "source": [
    "3. We aren't limited to the datasets that are already in BigQuery. We can upload tables from our computer, and we can pull data in from other online sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KpCJE78Cxpw4"
   },
   "source": [
    "## Google Gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y42HUkiyxpw4"
   },
   "source": [
    "Google Gemini (formerly Bard) is a multimodal generative AI chatbot. It can process text, audio, images and video.\n",
    "\n",
    "Create an API key at https://aistudio.google.com/app/apikey . Copy the key and paste it into a text file called 'gemini_key.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2778CTfIxpw4"
   },
   "source": [
    "## Google Gemini UI\n",
    "While signed into Google experiment with some prompts at https://aistudio.google.com/app/prompts/new_chat. A prompt gallery is available at https://aistudio.google.com/app/gallery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5VtWkTPixpw4"
   },
   "source": [
    "## Google Gemini API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1sr2VmOgxpw4"
   },
   "source": [
    "The library `google-generativeai` gives access to Gemini models. For this section download the following two files from the DATA folder:\n",
    "\n",
    "* `equation.jpg`\n",
    "* `JFK.mp3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "Wfv8zvH1xpw5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-generativeai\n",
      "  Downloading google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
      "  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from google-generativeai) (2.24.2)\n",
      "Collecting google-api-python-client (from google-generativeai)\n",
      "  Downloading google_api_python_client-2.173.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from google-generativeai) (2.38.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from google-generativeai) (5.29.4)\n",
      "Requirement already satisfied: pydantic in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from google-generativeai) (2.11.7)\n",
      "Requirement already satisfied: tqdm in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from google-generativeai) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from google-api-core->google-generativeai) (1.69.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Collecting httplib2<1.0.0,>=0.19.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai)\n",
      "  Downloading uritemplate-4.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from pydantic->google-generativeai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from pydantic->google-generativeai) (0.4.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\patri\\anaconda3\\envs\\cohort2\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\n",
      "Downloading google_generativeai-0.8.5-py3-none-any.whl (155 kB)\n",
      "Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.3/1.3 MB 9.7 MB/s eta 0:00:00\n",
      "Downloading google_api_python_client-2.173.0-py3-none-any.whl (13.6 MB)\n",
      "   ---------------------------------------- 0.0/13.6 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 2.4/13.6 MB 11.2 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 4.7/13.6 MB 10.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 6.8/13.6 MB 11.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 8.9/13.6 MB 10.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 11.3/13.6 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.4/13.6 MB 10.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.6/13.6 MB 10.4 MB/s eta 0:00:00\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Downloading uritemplate-4.2.0-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: uritemplate, httplib2, google-auth-httplib2, google-api-python-client, google-ai-generativelanguage, google-generativeai\n",
      "Successfully installed google-ai-generativelanguage-0.6.15 google-api-python-client-2.173.0 google-auth-httplib2-0.2.0 google-generativeai-0.8.5 httplib2-0.22.0 uritemplate-4.2.0\n"
     ]
    }
   ],
   "source": [
    "# -U gives the latest version\n",
    "!pip install -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "_rwuMn5Bxpw5"
   },
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from IPython.display import Markdown # allows Markdown text to be displayed in the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fLIKAdCwxpw5"
   },
   "source": [
    "Firstly we read our API key from `gemini_key.txt`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'C:/Users/patri/OneDrive/UTS and personal doc 2022/Documents/Person Docs/Data science program/Labs 3/gemini_key.txt'\n",
    "key = None\n",
    "\n",
    "try:\n",
    "    with open(filename, 'r') as f:\n",
    "        key = f.read().strip()\n",
    "except FileNotFoundError:\n",
    "    print(f\"'{filename}' file not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "57kbcoErxpw6"
   },
   "outputs": [],
   "source": [
    "genai.configure(api_key=key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oD4bAhVoxpw6"
   },
   "source": [
    "A list of methods in `google.generativeai` can be seen at https://github.com/google-gemini/generative-ai-python/blob/main/docs/api/google/generativeai.md. We shall use the following:\n",
    "\n",
    "* `configure()`: creates a client object by passing in the API key\n",
    "* `GenerativeModel()`: used to access the model\n",
    "  * `generate_content()`: used to generate responses from the model\n",
    "* `list_models()`: used to see available models\n",
    "* `upload_file()`: used to upload image/audio files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yLdPzZGMxpw6"
   },
   "source": [
    "The following code lists the available models for text generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object list_models at 0x0000010FB5808640>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genai.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "hGfNEiAuxpw7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-002\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-002\n",
      "models/gemini-1.5-flash-8b\n",
      "models/gemini-1.5-flash-8b-001\n",
      "models/gemini-1.5-flash-8b-latest\n",
      "models/gemini-2.5-pro-preview-03-25\n",
      "models/gemini-2.5-flash-preview-05-20\n",
      "models/gemini-2.5-flash\n",
      "models/gemini-2.5-flash-lite-preview-06-17\n",
      "models/gemini-2.5-pro-preview-05-06\n",
      "models/gemini-2.5-pro-preview-06-05\n",
      "models/gemini-2.5-pro\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-exp-image-generation\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-preview-image-generation\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-2.0-pro-exp\n",
      "models/gemini-2.0-pro-exp-02-05\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.0-flash-thinking-exp-01-21\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/gemini-2.5-flash-preview-tts\n",
      "models/gemini-2.5-pro-preview-tts\n",
      "models/learnlm-2.0-flash-experimental\n",
      "models/gemma-3-1b-it\n",
      "models/gemma-3-4b-it\n",
      "models/gemma-3-12b-it\n",
      "models/gemma-3-27b-it\n",
      "models/gemma-3n-e4b-it\n",
      "models/gemma-3n-e2b-it\n",
      "models/gemini-2.5-flash-lite\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "    if \"generateContent\" in m.supported_generation_methods:\n",
    "        print(m.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7gXcb3_axpw7"
   },
   "source": [
    "As suggested by the name, Gemini Flash is designed for faster responses while Gemini Pro works better at more challenging tasks. Pro has a lower rate limit of 2 requests per minute as seen in https://ai.google.dev/pricing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "nM7O6cazxpw7"
   },
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "response = model.generate_content(\"What is an API?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r25EuFCFxpw7"
   },
   "source": [
    "The attribute `text` shows in Markdown format the response of the model to the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "tVpmzYEXxpw7"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "API stands for **Application Programming Interface**.  It's essentially a messenger that allows software systems to talk to each other.  Think of it as a menu in a restaurant.  The menu (API) lists all the dishes (functions) the restaurant (software system) offers. You (another software system) can order (make a request) a specific dish (function) by selecting it from the menu, and the restaurant will prepare it (execute the function) and give it to you (return data).\n",
       "\n",
       "More formally, an API is a set of rules and specifications that software programs can follow to communicate and exchange information. It defines how one application can request services from another application and how the second application will respond.  This communication typically involves sending and receiving data in a structured format, often JSON or XML.\n",
       "\n",
       "**Key aspects of APIs:**\n",
       "\n",
       "* **Abstraction:**  APIs hide the complex internal workings of a system.  You don't need to know how the restaurant prepares the food, you just need to know what's on the menu and how to order.\n",
       "* **Standardization:**  APIs use standard formats and protocols, making it easier for different systems to interact, regardless of their underlying technology.\n",
       "* **Reusability:**  APIs allow developers to reuse existing functionality, saving time and resources.  Instead of building everything from scratch, they can leverage APIs to integrate with other services.\n",
       "\n",
       "\n",
       "**Examples of APIs in everyday life:**\n",
       "\n",
       "* **Google Maps API:**  Allows developers to integrate map functionalities into their applications.\n",
       "* **Twitter API:** Allows developers to access and interact with Twitter data and functionality (e.g., posting tweets, reading timelines).\n",
       "* **Payment Gateway APIs (like Stripe or PayPal):** Allow developers to integrate online payment processing into their websites or apps.\n",
       "* **Weather API:** Provides weather information to applications.\n",
       "\n",
       "\n",
       "In short, APIs are fundamental components of modern software development, enabling seamless integration and interaction between different applications and services.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7DKf8jEUxpw8"
   },
   "source": [
    "Study the response object and identify the total token count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "GWJKsCqvxpw8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "412"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ANSWER\n",
    "response.usage_metadata.total_token_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D4ArzGbKxpw8"
   },
   "source": [
    "Next, we have Gemini process a mathematical equation in an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "wcxC9JItxpw8"
   },
   "outputs": [],
   "source": [
    "sample_image = genai.upload_file(path=\"C:/Users/patri/OneDrive/UTS and personal doc 2022/Documents/Person Docs/Data science program/Labs 3/equation.jpg\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image = genai.upload_file(path=\"equation.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "oM27gjfJxpw8"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "That's a quadratic equation:  0 = x - 5x + 6.  It's set equal to zero, meaning it's ready to be solved for the values of *x*.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"What is in this image?\"\n",
    "Markdown(model.generate_content([prompt, sample_image]).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tuKbviaNxpw8"
   },
   "source": [
    "Use the Gemini 1.5 Pro model to solve the equation in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "eHIqvaj9xpw8"
   },
   "outputs": [
    {
     "ename": "ResourceExhausted",
     "evalue": "429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n}\nviolations {\n}\nviolations {\n}\n, links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, retry_delay {\n  seconds: 6\n}\n]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 7\u001b[0m\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m genai\u001b[38;5;241m.\u001b[39mGenerativeModel(model_name\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemini-1.5-pro\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m prompt \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease read the mathematical equation in this image and solve it step by step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 7\u001b[0m response \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate_content([prompt, sample_image])\n\u001b[0;32m      9\u001b[0m Markdown(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m response\u001b[38;5;241m.\u001b[39mtext)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Cohort2\\Lib\\site-packages\\google\\generativeai\\generative_models.py:331\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[1;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_iterator(iterator)\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mgenerate_content(\n\u001b[0;32m    332\u001b[0m             request,\n\u001b[0;32m    333\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest_options,\n\u001b[0;32m    334\u001b[0m         )\n\u001b[0;32m    335\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mInvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Cohort2\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:835\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[1;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[0;32m    834\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m--> 835\u001b[0m response \u001b[38;5;241m=\u001b[39m rpc(\n\u001b[0;32m    836\u001b[0m     request,\n\u001b[0;32m    837\u001b[0m     retry\u001b[38;5;241m=\u001b[39mretry,\n\u001b[0;32m    838\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    839\u001b[0m     metadata\u001b[38;5;241m=\u001b[39mmetadata,\n\u001b[0;32m    840\u001b[0m )\n\u001b[0;32m    842\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[0;32m    843\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Cohort2\\Lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Cohort2\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    292\u001b[0m )\n\u001b[1;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retry_target(\n\u001b[0;32m    294\u001b[0m     target,\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predicate,\n\u001b[0;32m    296\u001b[0m     sleep_generator,\n\u001b[0;32m    297\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout,\n\u001b[0;32m    298\u001b[0m     on_error\u001b[38;5;241m=\u001b[39mon_error,\n\u001b[0;32m    299\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Cohort2\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m     _retry_error_helper(\n\u001b[0;32m    154\u001b[0m         exc,\n\u001b[0;32m    155\u001b[0m         deadline,\n\u001b[0;32m    156\u001b[0m         sleep,\n\u001b[0;32m    157\u001b[0m         error_list,\n\u001b[0;32m    158\u001b[0m         predicate,\n\u001b[0;32m    159\u001b[0m         on_error,\n\u001b[0;32m    160\u001b[0m         exception_factory,\n\u001b[0;32m    161\u001b[0m         timeout,\n\u001b[0;32m    162\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Cohort2\\Lib\\site-packages\\google\\api_core\\retry\\retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[1;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[0;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[0;32m    208\u001b[0m         error_list,\n\u001b[0;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[0;32m    210\u001b[0m         original_timeout,\n\u001b[0;32m    211\u001b[0m     )\n\u001b[1;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Cohort2\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m target()\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[0;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Cohort2\\Lib\\site-packages\\google\\api_core\\timeout.py:130\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         remaining_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout\n\u001b[0;32m    128\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m remaining_timeout\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Cohort2\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mResourceExhausted\u001b[0m: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n}\nviolations {\n}\nviolations {\n}\n, links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, retry_delay {\n  seconds: 6\n}\n]"
     ]
    }
   ],
   "source": [
    "# REPLACE ??? with code\n",
    "model = genai.GenerativeModel(model_name= \"gemini-1.5-pro\")\n",
    "\n",
    "prompt =\"Please read the mathematical equation in this image and solve it step by step\"\n",
    " \n",
    "\n",
    "response = model.generate_content([prompt, sample_image])\n",
    "\n",
    "Markdown(\">\" + response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like this I have exhausted my resource usage on GEMINI API:\n",
    "\n",
    "means that your Gemini API usage has hit its limit for your current plan (likely the free tier). Specifically:\n",
    "\n",
    "You've made too many requests in a short period, or\n",
    "\n",
    "You've exceeded your daily/monthly quota, or\n",
    "\n",
    "You're using a model not available under your current quota (e.g. gemini-1.5-pro can have tighter restrictions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9luhD3Jnxpw9"
   },
   "source": [
    "Finally we transcribe a short audio clip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "IUO21JIuxpw9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vous mes amis, tant de fois vous me dites que d'ici peu je ne serais plus triste. J'aimerais bien vous croire un jour mais je doute avec raison. Essayez de rpondre  ma question. Qui saura, qui saura, qui saura, qui saura me faire oublier, dites-moi, ma seule raison de vivre. Essayez de me le dire. Qui saura, qui saura, oui qui saura ? Vous mes amis, essayez de comprendre. Une seule fille au monde peut me rendre tout ce que j'ai perdu. Je sais qu'elle ne reviendra pas. Alors si vous pouvez dites le moi. Qui saura, qui saura, qui saura, qui saura me faire vivre d'autres joie. Je n'avais qu'elle sur terre et sans elle ma vie entire. Je sais bien que le bonheur n'existe pas. Vous mes amis le soleil vous inonde. Vous dites que je sortirai de l'ombre. J'aimerais bien vous croire, oui, me manque qui renonce. Ma question reste toujours sans rponse. Qui saura, qui saura, qui saura. Qui saura me faire oublier dites-moi ma seule raison de vivre. Essayez de me le dire. Qui saura, qui saura, qui saura. Qui saura, qui saura, qui saura, qui saura me faire vivre d'autres joie. Je n'avais qu'elle sur terre et sans elle ma vie entire. Je sais bien que le bonheur n'existe pas. Qui saura, qui saura, qui saura. Qui saura me faire oublier dites moi. Ma seule raison de vivre, essayez de me le dire. Qui saura,\n"
     ]
    }
   ],
   "source": [
    "# REPLACE ??? with code\n",
    "audio_file = genai.upload_file(path='C:/Users/patri/OneDrive/UTS and personal doc 2022/Documents/Person Docs/Data science program/Labs 3/Qui saura.mp3')\n",
    "\n",
    "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")\n",
    "\n",
    "# Create a prompt.\n",
    "prompt = \"Transcribe the audio.\"\n",
    "\n",
    "# Pass the prompt and the audio file to Gemini using generate_content\n",
    "response = model.generate_content([prompt, audio_file])\n",
    "\n",
    "# Print the response.\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbB6B7r3QMqx"
   },
   "source": [
    "## Further reading\n",
    "\n",
    "If you wish to pick up a few more skills in BigQuery you can go to https://cloud.google.com/bigquery/create-simple-app-api and https://cloud.google.com/bigquery/docs/samples.\n",
    "\n",
    "Alternatively, you can take a deeper dive into the API here: https://googlecloudplatform.github.io/google-cloud-python/latest/bigquery/usage.html.\n",
    "\n",
    "The Google Gemini API documentation is at https://ai.google.dev/gemini-api/docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c6jzTfrZQMqx"
   },
   "source": [
    "## - END -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fWOk43cgN71c"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "> > > > > > > > >  2025 Institute of Data\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "BbB6B7r3QMqx"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
